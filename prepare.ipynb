{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc init -f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decouple compute and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'amlstorage' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d amlstorage gdrive://1zm71tPRrjEGLVeyPUIaxJ8ywhNaEtAk5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ujandasgupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ujandasgupta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "download('punkt')\n",
    "download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Convert text to lowercase, remove non-alphabetic characters,\n",
    "    and remove stopwords.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The email text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "    - str: The preprocessed email text.\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Re-join tokens into a single string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Apply text preprocessing to the 'text' column \n",
    "    data['text'] = data['text'].apply(preprocess_text)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, test_size=0.2, validation_size=0.25):\n",
    "    # Splitting data into train and temp data (which will be further split into validation and test)\n",
    "    train_data, temp_data = train_test_split(data, test_size=test_size, random_state=42)\n",
    "    # Adjusting validation size based on the new size of temp_data\n",
    "    validation_size_adjusted = validation_size / (1 - test_size)\n",
    "    validation_data, test_data = train_test_split(temp_data, test_size=validation_size_adjusted, random_state=42)\n",
    "    \n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_splits(train_data, validation_data, test_data, train_path='train.csv', validation_path='validation.csv', test_path='test.csv'):\n",
    "    train_data.to_csv(train_path, index=False)\n",
    "    validation_data.to_csv(validation_path, index=False)\n",
    "    test_data.to_csv(test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocess_data(data)\n",
    "train_data, validation_data, test_data = split_data(preprocessed_data)\n",
    "store_splits(train_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "  0% Adding...|                       | raw_data.csv |0/4 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in raw_data.csv |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding raw_data.csv to cache          0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      " 25% Adding...|█████▌                | train.csv |1/4 [00:00<00:01,  2.27file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in train.csv    |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding train.csv to cache             0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /Users/ujandasgupta/Deskt0/1 [00:00<?,    ?files/s]\u001b[A\n",
      " 25% Adding...|████▎            | validation.csv |1/4 [00:00<00:01,  2.27file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in validation.csv |0.00 [00:00,     ?file/\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding validation.csv to cache        0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /Users/ujandasgupta/Deskt0/1 [00:00<?,    ?files/s]\u001b[A\n",
      " 25% Adding...|█████▊                 | test.csv |1/4 [00:00<00:01,  2.27file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in test.csv     |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding test.csv to cache              0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /Users/ujandasgupta/Deskt0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|4/4 [00:00,  8.43file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add test.csv.dvc .gitignore raw_data.csv.dvc validation.csv.dvc train.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add raw_data.csv train.csv validation.csv test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .dvc/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main (root-commit) fb5e502] Configuring Google Drive as DVC remote storage for AML\n",
      " 3 files changed, 12 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Configuring Google Drive as DVC remote storage for AML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 0d90cfe] Tracking data with DVC\n",
      " 5 files changed, 24 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 raw_data.csv.dvc\n",
      " create mode 100644 test.csv.dvc\n",
      " create mode 100644 train.csv.dvc\n",
      " create mode 100644 validation.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Tracking data with DVC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc config core.autostage true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                           |4.00 [00:00, 1.10kentry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in '1zm71tPRrjEGLVeyPUIaxJ8ywhNaEtAk5/files/md5'| |0/? [00:0\u001b[A/opt/homebrew/Cellar/dvc/3.45.0/libexec/lib/python3.12/site-packages/oauth2client/_helpers.py:255: UserWarning: Cannot access /Users/ujandasgupta/Library/Caches/pydrive2fs/710796635688-iivsgbgsb6uv1fap6635dhvuei09o66c.apps.googleusercontent.com/default.json: No such file or directory\n",
      "  warnings.warn(_MISSING_FILE_MESSAGE.format(filename))\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=710796635688-iivsgbgsb6uv1fap6635dhvuei09o66c.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.appdata&access_type=offline&response_type=code&approval_prompt=force\n",
      "\n",
      "Authentication successful.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gdrive                     0/4 [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Pushing to gdrive                     0/4 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/Appl0.00/344k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         |/Users/ujandasgupta/Desktop8.00k/344k [00:04<03:16,    1.75kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      " 25%|██▌       |Pushing to gdrive                 1/4 [00:07<00:21,  7.18s/file]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/App0.00/8.54M [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/Appl0.00/751k [00:00<?,        ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "!\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/App0.00/4.26M [00:00<?,        ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Deskto8.00k/8.54M [00:02<38:20,    3.89kB/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         |/Users/ujandasgupta/Desktop712k/8.54M [00:02<00:18,     449kB/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       |/Users/ujandasgupta/Deskto2.05M/8.54M [00:02<00:05,    1.26MB/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     |/Users/ujandasgupta/Deskto3.96M/8.54M [00:02<00:01,    2.87MB/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   |/Users/ujandasgupta/Deskto5.79M/8.54M [00:02<00:00,    4.64MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          |/Users/ujandasgupta/Desktop8.00k/751k [00:03<04:49,    2.62kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▌ |/Users/ujandasgupta/Desktop/640k/751k [00:03<00:00,     281kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Deskto8.00k/4.26M [00:04<36:34,    2.03kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        |/Users/ujandasgupta/Desktop672k/4.26M [00:04<00:16,     232kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      |/Users/ujandasgupta/Deskto1.46M/4.26M [00:04<00:04,     609kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      " 50%|█████     |Pushing to gdrive                 2/4 [00:11<00:11,  5.50s/file]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▋  |/Users/ujandasgupta/Deskto3.26M/4.26M [00:04<00:00,    1.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      " 75%|███████▌  |Pushing to gdrive                 3/4 [00:12<00:03,  3.10s/file]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████|Pushing to gdrive                 4/4 [00:13<00:00,  2.32s/file]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "4 files pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Update the splits with a different random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, test_size=0.2, validation_size=0.25):\n",
    "    # Splitting data into train and temp data (which will be further split into validation and test)\n",
    "    train_data, temp_data = train_test_split(data, test_size=test_size, random_state=25)\n",
    "    # Adjusting validation size based on the new size of temp_data\n",
    "    validation_size_adjusted = validation_size / (1 - test_size)\n",
    "    validation_data, test_data = train_test_split(temp_data, test_size=validation_size_adjusted, random_state=42)\n",
    "    \n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the updated splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = split_data(preprocessed_data)\n",
    "store_splits(train_data, validation_data, test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the updated datasets to DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "  0% Adding...|                          | train.csv |0/3 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in train.csv    |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding train.csv to cache             0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /Users/ujandasgupta/Deskt0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "  0% Adding...|                     | validation.csv |0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in validation.csv |0.00 [00:00,     ?file/\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding validation.csv to cache        0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /Users/ujandasgupta/Deskt0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "  0% Adding...|                           | test.csv |0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in test.csv     |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding test.csv to cache              0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /Users/ujandasgupta/Deskt0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|3/3 [00:00, 91.99file/s]\u001b[A\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add train.csv validation.csv test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add train.csv.dvc validation.csv.dvc test.csv.dvc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main eacb60c] Updating data splits with new random seed\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Updating data splits with new random seed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                           |4.00 [00:00, 1.01kentry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in '1zm71tPRrjEGLVeyPUIaxJ8ywhNaEtAk5/files/md5'| |0/? [00:0\u001b[A\n",
      "  0% Querying cache in '1zm71tPRrjEGLVeyPUIaxJ8ywhNaEtAk5/files/md5'| |1/256 [00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/Users/ujandasgupta/Desktop/Applied ML/assignment-2/.dvc\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gdrive                     0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Pushing to gdrive                     0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/Appl0.00/317k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         |/Users/ujandasgupta/Desktop8.00k/317k [00:01<01:10,    4.47kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      " 33%|███▎      |Pushing to gdrive                 1/3 [00:03<00:06,  3.12s/file]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/Appl0.00/825k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "!\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Desktop/App0.00/4.22M [00:00<?,        ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          |/Users/ujandasgupta/Deskto8.00k/4.22M [00:01<16:52,    4.36kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▍        |/Users/ujandasgupta/Desktop640k/4.22M [00:02<00:08,     446kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     |/Users/ujandasgupta/Deskto1.93M/4.22M [00:02<00:01,    1.57MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|          |/Users/ujandasgupta/Desktop8.00k/825k [00:02<04:35,    3.04kB/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      |/Users/ujandasgupta/Desktop/296k/825k [00:02<00:03,     151kB/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ |/Users/ujandasgupta/Desktop/736k/825k [00:02<00:00,     442kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      " 67%|██████▋   |Pushing to gdrive                 2/3 [00:06<00:03,  3.30s/file]\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|██████████|Pushing to gdrive                 3/3 [00:07<00:00,  2.10s/file]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "3 files pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit eacb60c059e0635e0196f5f5fe81e5ac6129da1b\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Ujan Dasgupta <ujandasgupta@gmail.com>\n",
      "Date:   Mon Feb 19 15:16:04 2024 +0530\n",
      "\n",
      "    Updating data splits with new random seed\n",
      "\n",
      "\u001b[33mcommit 0d90cfee9769685ae54d3b905ef235818dd8dd71\u001b[m\n",
      "Author: Ujan Dasgupta <ujandasgupta@gmail.com>\n",
      "Date:   Mon Feb 19 15:12:30 2024 +0530\n",
      "\n",
      "    Tracking data with DVC\n",
      "\n",
      "\u001b[33mcommit fb5e502842bcc0aaf32697cbe4c3486ecb3d6d86\u001b[m\n",
      "Author: Ujan Dasgupta <ujandasgupta@gmail.com>\n",
      "Date:   Mon Feb 19 15:11:52 2024 +0530\n",
      "\n",
      "    Configuring Google Drive as DVC remote storage for AML\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <first_version_hash> = 0d90cfee9769685ae54d3b905ef235818dd8dd71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 3 paths from a6865c1\n"
     ]
    }
   ],
   "source": [
    "!git checkout 0d90cfee9769685ae54d3b905ef235818dd8dd71 train.csv.dvc validation.csv.dvc test.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workspace index                              |4.00 [00:00,  475entry/s]\n",
      "Comparing indexes                                    |5.00 [00:00, 6.92kentry/s]\n",
      "Applying changes                                      |3.00 [00:00, 2.49kfile/s]\n",
      "\u001b[33mM\u001b[0m       validation.csv\n",
      "\u001b[33mM\u001b[0m       train.csv\n",
      "\u001b[33mM\u001b[0m       test.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing Distribution of the original data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution in train.csv: \n",
      "spam\n",
      "0    3504\n",
      "1    1078\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution in validation.csv: \n",
      "spam\n",
      "0    589\n",
      "1    198\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution in test.csv: \n",
      "spam\n",
      "0    267\n",
      "1     92\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of data splits\n",
    "splits = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each split and print the distribution\n",
    "for split in splits:\n",
    "    # Load the dataset from CSV file\n",
    "    df = pd.read_csv(f'{split}.csv')\n",
    "    # Get the distribution of the 'spam' column\n",
    "    distribution = df['spam'].value_counts()\n",
    "    # Print the distribution for the current split\n",
    "    print(f\"Distribution in {split}.csv: \\n{distribution}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <updated_version_hash> = eacb60c059e0635e0196f5f5fe81e5ac6129da1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 3 paths from 59b3e61\n"
     ]
    }
   ],
   "source": [
    "!git checkout eacb60c059e0635e0196f5f5fe81e5ac6129da1b train.csv.dvc validation.csv.dvc test.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workspace index                              |4.00 [00:00,  456entry/s]\n",
      "Comparing indexes                                    |5.00 [00:00, 7.40kentry/s]\n",
      "Applying changes                                      |3.00 [00:00, 2.46kfile/s]\n",
      "\u001b[33mM\u001b[0m       train.csv\n",
      "\u001b[33mM\u001b[0m       test.csv\n",
      "\u001b[33mM\u001b[0m       validation.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the distribution of the Updated data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution in train.csv: \n",
      "spam\n",
      "0    3495\n",
      "1    1087\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution in validation.csv: \n",
      "spam\n",
      "0    582\n",
      "1    205\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution in test.csv: \n",
      "spam\n",
      "0    283\n",
      "1     76\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of data splits\n",
    "splits = ['train', 'validation', 'test']\n",
    "\n",
    "# Loop through each split and print the distribution\n",
    "for split in splits:\n",
    "    # Load the dataset from CSV file\n",
    "    df = pd.read_csv(f'{split}.csv')\n",
    "    # Get the distribution of the 'spam' column\n",
    "    distribution = df['spam'].value_counts()\n",
    "    # Print the distribution for the current split\n",
    "    print(f\"Distribution in {split}.csv: \\n{distribution}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1223e1bb6f70b4e85dab1ecdac04c42cbf45c1eafc17bc1f0f72cf403c1b7f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
